{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>No noticable damages observed from exterior, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Green</td>\n",
       "      <td>Cracks in wood ridge beam appear to be ordinar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Green</td>\n",
       "      <td>Cracks in GYPBD, roof beam @ porch &amp; interior ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Green</td>\n",
       "      <td>minor cracks in chimney - home appears safe an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>No use of front porch except to enter /exit home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                              texts\n",
       "0  Yellow  No noticable damages observed from exterior, c...\n",
       "1   Green  Cracks in wood ridge beam appear to be ordinar...\n",
       "2   Green  Cracks in GYPBD, roof beam @ porch & interior ...\n",
       "3   Green  minor cracks in chimney - home appears safe an...\n",
       "4  Yellow   No use of front porch except to enter /exit home"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "\n",
    "data = pd.read_excel('Napa_data_excel.xlsx', sheet_name='Sheet1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some damage descriptions are missing, lets remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['texts'].replace(' ', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3677, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels      0\n",
       "texts     254\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking missing values by column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "254 missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 2)\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25457"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texts'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_tags = ['Green','Yellow','Red']\n",
    "plt.figure(figsize=(10,4))\n",
    "data.labels.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_plot(index):\n",
    "    example = data[data.index == index][['texts', 'labels']].values[0]\n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('Label', example[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no placard placed - minor stucco cracks\n",
      "Label Green\n"
     ]
    }
   ],
   "source": [
    "print_plot(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean the data by removing special characters, and using stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sujit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['texts'] = data['texts'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "import chart_studio\n",
    "import chart_studio.plotly as py\n",
    "import cufflinks\n",
    "pd.options.display.max_columns = 30\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import plotly.figure_factory as ff\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from plotly.offline import iplot\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_count'] = data['texts'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "histfunc": "count",
         "histnorm": "",
         "marker": {
          "color": "rgba(255, 153, 51, 1.0)",
          "line": {
           "color": "#000000",
           "width": 1.3
          }
         },
         "name": "word_count",
         "nbinsx": 100,
         "opacity": 0.8,
         "orientation": "v",
         "type": "histogram",
         "x": [
          9,
          8,
          8,
          7,
          7,
          3,
          6,
          2,
          16,
          19,
          5,
          8,
          8,
          2,
          2,
          2,
          5,
          14,
          11,
          8,
          7,
          10,
          7,
          4,
          4,
          9,
          7,
          5,
          13,
          1,
          2,
          4,
          7,
          18,
          17,
          9,
          6,
          4,
          18,
          2,
          11,
          4,
          7,
          4,
          5,
          1,
          3,
          3,
          2,
          10,
          6,
          7,
          8,
          12,
          2,
          7,
          19,
          8,
          14,
          5,
          5,
          7,
          8,
          6,
          8,
          4,
          4,
          8,
          2,
          10,
          5,
          3,
          8,
          2,
          1,
          6,
          14,
          1,
          16,
          1,
          11,
          9,
          8,
          7,
          7,
          3,
          11,
          7,
          12,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          5,
          11,
          10,
          1,
          7,
          2,
          10,
          8,
          5,
          8,
          2,
          5,
          11,
          2,
          7,
          1,
          10,
          1,
          1,
          7,
          3,
          3,
          1,
          2,
          4,
          4,
          2,
          7,
          4,
          7,
          2,
          3,
          6,
          14,
          3,
          4,
          5,
          4,
          2,
          11,
          2,
          14,
          3,
          6,
          11,
          10,
          7,
          4,
          15,
          10,
          4,
          4,
          12,
          4,
          4,
          9,
          6,
          15,
          3,
          2,
          3,
          4,
          1,
          8,
          5,
          3,
          5,
          22,
          5,
          3,
          5,
          9,
          1,
          1,
          1,
          2,
          1,
          4,
          12,
          3,
          4,
          19,
          21,
          16,
          7,
          5,
          5,
          10,
          6,
          10,
          14,
          14,
          3,
          3,
          3,
          13,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          11,
          2,
          3,
          2,
          10,
          6,
          3,
          3,
          2,
          7,
          2,
          2,
          4,
          4,
          3,
          1,
          1,
          4,
          5,
          2,
          7,
          3,
          3,
          6,
          1,
          3,
          13,
          7,
          7,
          7,
          2,
          2,
          4,
          12,
          5,
          1,
          1,
          2,
          8,
          4,
          6,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          8,
          3,
          3,
          4,
          2,
          2,
          2,
          2,
          4,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          8,
          4,
          10,
          1,
          7,
          5,
          7,
          7,
          4,
          4,
          13,
          8,
          19,
          2,
          10,
          5,
          3,
          2,
          2,
          2,
          3,
          6,
          10,
          2,
          2,
          4,
          5,
          2,
          2,
          10,
          7,
          11,
          2,
          1,
          7,
          2,
          18,
          2,
          12,
          5,
          2,
          1,
          8,
          10,
          15,
          2,
          12,
          2,
          5,
          5,
          2,
          6,
          1,
          10,
          11,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          4,
          12,
          1,
          7,
          13,
          2,
          6,
          13,
          1,
          6,
          5,
          2,
          16,
          4,
          13,
          6,
          1,
          3,
          3,
          11,
          5,
          15,
          3,
          3,
          6,
          9,
          5,
          7,
          1,
          1,
          1,
          5,
          2,
          8,
          2,
          8,
          17,
          2,
          8,
          16,
          1,
          4,
          5,
          4,
          2,
          12,
          4,
          2,
          9,
          3,
          3,
          17,
          10,
          2,
          4,
          11,
          10,
          6,
          7,
          11,
          2,
          1,
          5,
          2,
          12,
          5,
          10,
          15,
          1,
          1,
          8,
          8,
          8,
          8,
          6,
          1,
          10,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          13,
          15,
          11,
          1,
          2,
          1,
          1,
          1,
          3,
          14,
          4,
          4,
          4,
          7,
          3,
          7,
          5,
          8,
          19,
          13,
          3,
          7,
          6,
          2,
          4,
          2,
          5,
          4,
          4,
          20,
          4,
          2,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          4,
          4,
          7,
          19,
          6,
          4,
          8,
          11,
          3,
          3,
          2,
          2,
          2,
          2,
          7,
          7,
          7,
          7,
          7,
          7,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          5,
          7,
          2,
          13,
          9,
          2,
          14,
          5,
          4,
          1,
          2,
          8,
          13,
          4,
          13,
          11,
          8,
          1,
          5,
          7,
          5,
          3,
          7,
          4,
          3,
          3,
          5,
          1,
          1,
          22,
          5,
          3,
          3,
          3,
          3,
          7,
          2,
          9,
          6,
          4,
          8,
          8,
          4,
          5,
          8,
          15,
          8,
          15,
          8,
          8,
          15,
          2,
          8,
          15,
          8,
          4,
          7,
          10,
          4,
          13,
          1,
          13,
          9,
          2,
          3,
          17,
          8,
          13,
          2,
          12,
          5,
          3,
          7,
          7,
          6,
          7,
          2,
          3,
          1,
          6,
          18,
          3,
          1,
          1,
          4,
          1,
          1,
          17,
          14,
          19,
          4,
          21,
          4,
          8,
          10,
          5,
          1,
          1,
          4,
          3,
          9,
          2,
          8,
          2,
          8,
          2,
          8,
          1,
          2,
          8,
          1,
          2,
          3,
          4,
          4,
          3,
          7,
          15,
          7,
          3,
          5,
          7,
          10,
          8,
          3,
          5,
          7,
          6,
          5,
          6,
          5,
          5,
          14,
          2,
          4,
          1,
          8,
          10,
          11,
          15,
          18,
          12,
          15,
          5,
          5,
          2,
          9,
          7,
          5,
          5,
          5,
          5,
          4,
          11,
          2,
          7,
          4,
          4,
          11,
          9,
          1,
          4,
          4,
          1,
          2,
          5,
          2,
          4,
          1,
          9,
          16,
          3,
          5,
          2,
          3,
          2,
          5,
          3,
          10,
          1,
          8,
          9,
          6,
          3,
          4,
          4,
          1,
          6,
          10,
          9,
          4,
          6,
          7,
          4,
          2,
          9,
          11,
          5,
          5,
          12,
          4,
          4,
          11,
          1,
          4,
          2,
          8,
          1,
          4,
          1,
          3,
          1,
          9,
          3,
          13,
          6,
          2,
          5,
          3,
          3,
          3,
          3,
          2,
          1,
          12,
          3,
          7,
          1,
          2,
          3,
          3,
          1,
          9,
          1,
          11,
          1,
          13,
          15,
          6,
          1,
          1,
          5,
          1,
          1,
          1,
          3,
          8,
          10,
          10,
          5,
          5,
          7,
          1,
          5,
          1,
          1,
          8,
          8,
          5,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          12,
          3,
          1,
          12,
          3,
          4,
          6,
          5,
          6,
          4,
          14,
          6,
          17,
          4,
          4,
          4,
          4,
          8,
          8,
          7,
          6,
          5,
          5,
          4,
          10,
          5,
          9,
          1,
          12,
          5,
          9,
          3,
          2,
          1,
          15,
          2,
          7,
          2,
          2,
          9,
          1,
          4,
          9,
          1,
          6,
          7,
          7,
          1,
          4,
          2,
          8,
          5,
          8,
          3,
          2,
          2,
          2,
          2,
          10,
          10,
          16,
          2,
          2,
          6,
          2,
          1,
          6,
          4,
          8,
          6,
          12,
          7,
          5,
          1,
          1,
          2,
          2,
          3,
          1,
          1,
          2,
          2,
          8,
          2,
          9,
          10,
          9,
          10,
          8,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          6,
          5,
          6,
          1,
          5,
          5,
          2,
          3,
          4,
          2,
          2,
          2,
          2,
          8,
          9,
          3,
          10,
          1,
          4,
          8,
          8,
          8,
          1,
          1,
          15,
          2,
          2,
          6,
          4,
          16,
          1,
          1,
          1,
          3,
          1,
          2,
          8,
          1,
          8,
          4,
          11,
          4,
          10,
          3,
          1,
          2,
          2,
          2,
          2,
          4,
          5,
          10,
          9,
          5,
          4,
          2,
          7,
          4,
          3,
          1,
          3,
          1,
          3,
          1,
          9,
          3,
          7,
          2,
          6,
          2,
          2,
          4,
          2,
          5,
          2,
          9,
          3,
          1,
          9,
          10,
          8,
          9,
          4,
          5,
          14,
          9,
          3,
          2,
          2,
          2,
          6,
          2,
          2,
          2,
          4,
          1,
          1,
          1,
          3,
          3,
          1,
          11,
          4,
          4,
          10,
          18,
          4,
          6,
          10,
          5,
          5,
          3,
          16,
          2,
          12,
          7,
          3,
          3,
          6,
          4,
          9,
          3,
          17,
          8,
          7,
          3,
          2,
          15,
          14,
          11,
          7,
          5,
          1,
          2,
          2,
          2,
          2,
          12,
          9,
          4,
          2,
          12,
          3,
          1,
          1,
          1,
          1,
          1,
          3,
          11,
          2,
          10,
          4,
          3,
          9,
          17,
          3,
          9,
          6,
          2,
          6,
          3,
          6,
          11,
          6,
          6,
          1,
          12,
          12,
          12,
          12,
          3,
          4,
          4,
          9,
          9,
          13,
          5,
          12,
          6,
          4,
          4,
          8,
          4,
          11,
          9,
          16,
          10,
          8,
          5,
          8,
          7,
          5,
          1,
          15,
          4,
          3,
          1,
          1,
          6,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          7,
          4,
          4,
          2,
          4,
          2,
          2,
          2,
          2,
          2,
          6,
          6,
          9,
          3,
          2,
          2,
          2,
          1,
          20,
          12,
          5,
          2,
          1,
          1,
          4,
          14,
          9,
          12,
          3,
          5,
          9,
          3,
          2,
          1,
          13,
          6,
          14,
          4,
          6,
          8,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          1,
          2,
          11,
          14,
          16,
          1,
          1,
          5,
          2,
          2,
          2,
          2,
          2,
          2,
          6,
          2,
          2,
          2,
          2,
          2,
          12,
          5,
          5,
          8,
          2,
          3,
          3,
          3,
          5,
          9,
          5,
          5,
          13,
          5,
          7,
          1,
          9,
          1,
          13,
          3,
          8,
          1,
          2,
          2,
          2,
          2,
          2,
          9,
          5,
          4,
          7,
          8,
          9,
          11,
          8,
          6,
          1,
          12,
          15,
          18,
          12,
          15,
          18,
          12,
          18,
          6,
          1,
          4,
          2,
          1,
          4,
          1,
          1,
          18,
          9,
          4,
          8,
          8,
          8,
          8,
          8,
          8,
          10,
          1,
          5,
          8,
          3,
          2,
          1,
          1,
          1,
          5,
          8,
          8,
          4,
          20,
          1,
          1,
          2,
          1,
          1,
          8,
          6,
          2,
          7,
          1,
          1,
          1,
          4,
          1,
          4,
          2,
          17,
          9,
          9,
          6,
          3,
          10,
          4,
          10,
          9,
          4,
          4,
          4,
          12,
          4,
          1,
          10,
          1,
          7,
          3,
          3,
          4,
          8,
          4,
          2,
          5,
          5,
          1,
          3,
          9,
          15,
          15,
          12,
          16,
          5,
          4,
          1,
          5,
          2,
          7,
          7,
          6,
          3,
          3,
          4,
          4,
          4,
          5,
          11,
          4,
          16,
          4,
          6,
          1,
          6,
          3,
          16,
          1,
          10,
          1,
          2,
          5,
          3,
          4,
          6,
          5,
          8,
          8,
          3,
          3,
          3,
          7,
          7,
          3,
          3,
          5,
          3,
          11,
          8,
          5,
          6,
          2,
          13,
          13,
          3,
          3,
          10,
          1,
          1,
          16,
          8,
          8,
          2,
          7,
          15,
          6,
          11,
          7,
          11,
          4,
          4,
          7,
          18,
          2,
          3,
          1,
          2,
          7,
          6,
          3,
          9,
          3,
          4,
          9,
          6,
          4,
          5,
          13,
          4,
          14,
          3,
          6,
          2,
          8,
          16,
          2,
          7,
          5,
          10,
          6,
          6,
          9,
          2,
          13,
          1,
          4,
          14,
          1,
          4,
          2,
          17,
          1,
          10,
          14,
          2,
          9,
          2,
          2,
          4,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          5,
          2,
          6,
          18,
          18,
          10,
          7,
          18,
          18,
          10,
          10,
          10,
          10,
          10,
          10,
          2,
          4,
          4,
          6,
          5,
          7,
          6,
          5,
          12,
          6,
          2,
          11,
          4,
          12,
          3,
          14,
          15,
          2,
          2,
          2,
          1,
          4,
          10,
          8,
          1,
          4,
          6,
          15,
          1,
          2,
          5,
          20,
          13,
          1,
          1,
          4,
          1,
          16,
          14,
          14,
          6,
          17,
          7,
          9,
          8,
          5,
          2,
          2,
          6,
          6,
          6,
          6,
          7,
          4,
          2,
          16,
          1,
          2,
          2,
          4,
          9,
          6,
          7,
          1,
          6,
          6,
          7,
          5,
          1,
          10,
          4,
          4,
          3,
          5,
          4,
          3,
          5,
          12,
          5,
          10,
          14,
          5,
          6,
          6,
          3,
          4,
          8,
          4,
          6,
          4,
          12,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          11,
          10,
          4,
          3,
          7,
          4,
          4,
          14,
          15,
          3,
          3,
          3,
          3,
          3,
          3,
          7,
          7,
          3,
          2,
          3,
          4,
          4,
          7,
          3,
          3,
          8,
          2,
          3,
          9,
          3,
          11,
          6,
          8,
          7,
          4,
          4,
          4,
          8,
          9,
          1,
          8,
          4,
          6,
          3,
          7,
          5,
          1,
          13,
          2,
          9,
          2,
          2,
          1,
          3,
          3,
          2,
          9,
          1,
          1,
          4,
          2,
          4,
          1,
          7,
          8,
          7,
          5,
          5,
          10,
          3,
          10,
          10,
          5,
          7,
          9,
          4,
          10,
          2,
          2,
          4,
          6,
          7,
          7,
          7,
          5,
          10,
          7,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          19,
          10,
          11,
          1,
          16,
          1,
          6,
          9,
          4,
          1,
          3,
          3,
          3,
          3,
          17,
          8,
          4,
          3,
          4,
          2,
          7,
          2,
          2,
          3,
          2,
          3,
          2,
          3,
          14,
          3,
          8,
          2,
          9,
          3,
          4,
          5,
          5,
          5,
          5,
          6,
          4,
          4,
          9,
          1,
          11,
          4,
          3,
          8,
          8,
          15,
          2,
          2,
          11,
          6,
          4,
          18,
          1,
          6,
          14,
          3,
          2,
          9,
          7,
          4,
          2,
          10,
          8,
          9,
          9,
          8,
          9,
          10,
          1,
          8,
          2,
          4,
          5,
          2,
          5,
          5,
          1,
          1,
          9,
          12,
          6,
          3,
          9,
          2,
          12,
          10,
          2,
          1,
          4,
          3,
          3,
          3,
          3,
          3,
          19,
          10,
          2,
          4,
          2,
          2,
          4,
          10,
          1,
          1,
          2,
          18,
          2,
          2,
          4,
          9,
          6,
          4,
          3,
          6,
          6,
          6,
          9,
          6,
          3,
          3,
          2,
          4,
          4,
          2,
          1,
          3,
          2,
          4,
          2,
          3,
          5,
          2,
          6,
          4,
          3,
          4,
          7,
          3,
          9,
          2,
          10,
          6,
          4,
          7,
          6,
          11,
          5,
          1,
          1,
          11,
          3,
          4,
          10,
          19,
          4,
          8,
          2,
          11,
          4,
          10,
          16,
          6,
          6,
          2,
          2,
          2,
          3,
          2,
          2,
          19,
          2,
          7,
          7,
          2,
          2,
          11,
          9,
          2,
          3,
          4,
          4,
          6,
          2,
          6,
          2,
          2,
          2,
          12,
          9,
          2,
          5,
          2,
          3,
          15,
          2,
          5,
          8,
          6,
          6,
          8,
          3,
          3,
          6,
          1,
          6,
          13,
          4,
          4,
          2,
          20,
          5,
          5,
          5,
          17,
          1,
          2,
          2,
          2,
          2,
          1,
          10,
          4,
          6,
          5,
          7,
          9,
          6,
          4,
          10,
          3,
          5,
          3,
          1,
          5,
          2,
          5,
          7,
          4,
          2,
          5,
          5,
          4,
          8,
          1,
          2,
          15,
          15,
          8,
          11,
          1,
          11,
          11,
          11,
          5,
          6,
          11,
          11,
          5,
          6,
          9,
          2,
          6,
          9,
          1,
          1,
          1,
          7,
          7,
          13,
          1,
          9,
          2,
          5,
          5,
          5,
          5,
          3,
          9,
          2,
          7,
          7,
          2,
          4,
          2,
          2,
          6,
          1,
          2,
          6,
          6,
          1,
          2,
          3,
          10,
          2,
          3,
          2,
          3,
          2,
          2,
          2,
          2,
          3,
          2,
          13,
          3,
          5,
          5,
          1,
          1,
          8,
          8,
          8,
          8,
          16,
          6,
          2,
          15,
          10,
          4,
          8,
          3,
          2,
          1,
          7,
          2,
          7,
          6,
          3,
          1,
          8,
          4,
          5,
          2,
          3,
          9,
          3,
          6,
          8,
          5,
          1,
          1,
          1,
          5,
          5,
          2,
          7,
          1,
          2,
          11,
          4,
          2,
          2,
          5,
          3,
          2,
          12,
          2,
          4,
          5,
          3,
          7,
          18,
          9,
          4,
          2,
          7,
          13,
          20,
          6,
          6,
          3,
          5,
          11,
          2,
          14,
          14,
          6,
          3,
          4,
          9,
          5,
          5,
          4,
          8,
          1,
          5,
          6,
          2,
          9,
          5,
          6,
          5,
          2,
          1,
          1,
          12,
          2,
          5,
          7,
          5,
          11,
          6,
          2,
          3,
          2,
          5,
          1,
          2,
          2,
          2,
          2,
          6,
          6,
          6,
          1,
          3,
          1,
          8,
          12,
          5,
          5,
          5,
          15,
          8,
          1,
          4,
          4,
          1,
          4,
          1,
          5,
          2,
          11,
          2,
          14,
          11,
          12,
          3,
          13,
          10,
          2,
          1,
          3,
          7,
          4,
          2,
          11,
          5,
          2,
          8,
          2,
          2,
          6,
          6,
          2,
          2,
          4,
          11,
          5,
          11,
          7,
          5,
          7,
          5,
          5,
          1,
          1,
          4,
          7,
          6,
          4,
          4,
          6,
          6,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          1,
          4,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          7,
          14,
          4,
          12,
          5,
          9,
          3,
          12,
          5,
          2,
          1,
          3,
          3,
          2,
          6,
          15,
          6,
          9,
          21,
          13,
          2,
          3,
          3,
          2,
          3,
          6,
          11,
          8,
          11,
          5,
          6,
          10,
          1,
          2,
          2,
          7,
          1,
          8,
          1,
          1,
          7,
          8,
          2,
          1,
          2,
          2,
          4,
          17,
          16,
          5,
          3,
          1,
          3,
          7,
          2,
          10,
          1,
          6,
          3,
          3,
          13,
          2,
          4,
          3,
          11,
          7,
          8,
          8,
          3,
          13,
          5,
          5,
          14,
          11,
          3,
          4,
          10,
          2,
          3,
          1,
          1,
          14,
          14,
          13,
          4,
          5,
          5,
          16,
          10,
          3,
          5,
          3,
          10,
          1,
          6,
          5,
          15,
          10,
          6,
          11,
          2,
          2,
          2,
          3,
          4,
          2,
          10,
          4,
          3,
          9,
          1,
          11,
          13,
          13,
          3,
          2,
          1,
          14,
          18,
          9,
          4,
          5,
          3,
          14,
          8,
          2,
          8,
          2,
          2,
          4,
          2,
          15,
          7,
          3,
          7,
          18,
          6,
          6,
          6,
          7,
          8,
          9,
          6,
          4,
          1,
          1,
          6,
          10,
          1,
          4,
          3,
          7,
          12,
          7,
          5,
          1,
          7,
          3,
          14,
          9,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          1,
          3,
          3,
          3,
          4,
          2,
          24,
          6,
          11,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          7,
          5,
          11,
          4,
          4,
          7,
          2,
          5,
          5,
          2,
          16,
          2,
          14,
          2,
          13,
          6,
          4,
          3,
          3,
          7,
          5,
          4,
          3,
          2,
          2,
          2,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          2,
          2,
          5,
          2,
          1,
          2,
          2,
          14,
          14,
          2,
          1,
          12,
          5,
          6,
          2,
          8,
          13,
          3,
          5,
          5,
          5,
          9,
          7,
          7,
          7,
          7,
          2,
          3,
          1,
          2,
          4,
          19,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          5,
          2,
          2,
          2,
          1,
          12,
          5,
          1,
          6,
          1,
          1,
          5,
          2,
          2,
          4,
          3,
          4,
          3,
          7,
          6,
          10,
          4,
          1,
          8,
          3,
          16,
          2,
          14,
          7,
          2,
          5,
          17,
          3,
          2,
          7,
          19,
          19,
          4,
          10,
          7,
          10,
          6,
          5,
          4,
          1,
          1,
          10,
          4,
          3,
          4,
          4,
          4,
          4,
          1,
          10,
          14,
          2,
          7,
          3,
          4,
          3,
          3,
          8,
          9,
          3,
          2,
          2,
          2,
          3,
          9,
          2,
          4,
          4,
          1,
          6,
          8,
          8,
          1,
          3,
          1,
          9,
          2,
          12,
          11,
          12,
          9,
          19,
          3,
          2,
          4,
          4,
          14,
          4,
          5,
          2,
          10,
          2,
          2,
          2,
          2,
          2,
          2,
          11,
          6,
          6,
          1,
          8,
          8,
          2,
          1,
          8,
          5,
          1,
          5,
          12,
          6,
          3,
          11,
          7,
          6,
          8,
          7,
          7,
          7,
          7,
          7,
          8,
          10,
          1,
          1,
          3,
          1,
          6,
          11,
          8,
          6,
          5,
          4,
          11,
          3,
          3,
          14,
          2,
          3,
          1,
          2,
          7,
          2,
          1,
          10,
          14,
          7,
          10,
          9,
          9,
          4,
          4,
          1,
          8,
          5,
          1,
          1,
          1,
          2,
          5,
          4,
          11,
          7,
          8,
          1,
          6,
          9,
          16,
          5,
          5,
          5,
          5,
          5,
          5,
          2,
          3,
          4,
          9,
          5,
          4,
          4,
          4,
          4,
          13,
          5,
          10,
          1,
          9,
          5,
          3,
          9,
          6,
          14,
          5,
          2,
          2,
          5,
          3,
          4,
          4,
          3,
          10,
          9,
          11,
          4,
          2,
          2,
          3,
          3,
          3,
          3,
          9,
          18,
          7,
          1,
          16,
          3,
          1,
          9,
          9,
          6,
          17,
          9,
          11,
          6,
          1,
          4,
          8,
          8,
          2,
          1,
          16,
          2,
          5,
          1,
          1,
          4,
          9,
          14,
          3,
          8,
          4,
          5,
          2,
          10,
          2,
          8,
          8,
          3,
          6,
          3,
          4,
          5,
          5,
          4,
          2,
          11,
          15,
          5,
          7,
          2,
          11,
          2,
          1,
          1,
          8,
          14,
          19,
          2,
          3,
          4,
          4,
          7,
          1,
          1,
          4,
          5,
          5,
          4,
          8,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          9,
          4,
          5,
          5,
          9,
          8,
          9,
          5,
          2,
          8,
          5,
          12,
          9,
          19,
          19,
          11,
          7,
          20,
          5,
          12,
          6,
          2,
          1,
          5,
          2,
          3,
          6,
          8,
          8,
          4,
          7,
          2,
          7,
          9,
          5,
          5,
          2,
          5,
          2,
          13,
          16,
          15,
          1,
          6,
          4,
          10,
          2,
          15,
          1,
          9,
          2,
          19,
          3,
          1,
          3,
          2,
          3,
          3,
          2,
          4,
          5,
          2,
          2,
          2,
          4,
          2,
          4,
          7,
          1,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          18,
          2,
          1,
          3,
          2,
          1,
          6,
          4,
          8,
          5,
          11,
          4,
          11,
          7,
          2,
          15,
          2,
          1,
          2,
          1,
          10,
          2,
          2,
          3,
          3,
          5,
          2,
          5,
          2,
          22,
          8,
          1,
          11,
          3,
          3,
          6,
          6,
          2,
          12,
          2,
          12,
          2,
          12,
          3,
          12,
          3,
          3,
          3,
          2,
          2,
          2,
          2,
          2,
          1,
          3,
          13,
          13,
          2,
          7,
          2,
          3,
          2,
          4,
          11,
          1,
          4,
          1,
          1,
          6,
          4,
          10,
          9,
          10,
          23,
          15,
          2,
          12,
          3,
          7,
          12,
          13,
          5,
          6,
          7,
          4,
          3,
          15,
          3,
          7,
          1,
          2,
          1,
          7,
          11,
          1,
          12,
          16,
          2,
          2,
          2,
          2,
          16,
          4,
          15,
          14,
          12,
          4,
          13,
          5,
          1,
          1,
          3,
          1,
          3,
          1,
          1,
          5,
          11,
          1,
          1,
          3,
          3,
          6,
          2,
          10,
          8,
          21,
          12,
          6,
          5,
          2,
          4,
          5,
          4,
          2,
          4,
          5,
          9,
          4,
          4,
          1,
          2,
          2,
          2,
          4,
          1,
          1,
          7,
          4,
          12,
          2,
          2,
          2,
          2,
          10,
          1,
          2,
          2,
          2,
          2,
          7,
          7,
          7,
          7,
          7,
          4,
          7,
          7,
          2,
          7,
          7,
          7,
          3,
          7,
          2,
          7,
          1,
          5,
          5,
          8,
          2,
          3,
          5,
          7,
          17,
          4,
          3,
          2,
          2,
          9,
          7,
          7,
          5,
          18,
          3,
          6,
          12,
          3,
          14,
          2,
          7,
          3,
          3,
          1,
          5,
          5,
          5,
          3,
          11,
          13,
          2,
          4,
          9,
          1,
          4,
          2,
          4,
          3,
          5,
          4,
          10,
          7,
          13,
          4,
          14,
          2,
          2,
          11,
          5,
          5,
          6,
          5,
          1,
          2,
          19,
          5,
          4,
          7,
          11,
          3,
          4,
          9,
          5,
          3,
          6,
          3,
          5,
          9,
          8,
          2,
          2,
          2,
          8,
          7,
          7,
          1,
          5,
          2,
          2,
          2,
          4,
          13,
          11,
          1,
          13,
          2,
          11,
          10,
          20,
          9,
          2,
          12,
          8,
          9,
          1,
          7,
          8,
          8,
          11,
          2,
          7,
          3,
          8,
          3,
          6,
          10,
          2,
          7,
          7,
          6,
          1,
          4,
          1,
          1,
          3,
          10,
          4,
          4,
          4,
          4,
          3,
          3,
          6,
          2,
          2,
          4,
          11,
          4,
          2,
          4,
          2,
          6,
          1,
          2,
          2,
          1,
          2,
          2,
          11,
          8,
          8,
          5,
          7,
          10,
          13,
          10,
          13,
          6,
          4,
          5,
          6,
          19,
          17,
          15,
          3,
          3,
          9,
          2,
          2,
          3,
          1,
          6,
          10,
          16,
          10,
          6,
          1,
          1,
          7,
          11,
          18,
          7,
          1,
          9,
          9,
          1,
          5,
          9,
          3,
          9,
          3,
          1,
          3,
          4,
          4,
          18,
          4,
          4,
          2,
          10,
          10,
          1,
          13,
          3,
          3,
          12,
          2,
          2,
          2,
          5,
          5,
          5,
          6,
          11,
          3,
          9,
          16,
          20,
          6,
          18,
          3,
          3,
          8,
          8,
          4,
          17,
          8,
          11,
          16,
          2,
          2,
          14,
          6,
          6,
          2,
          2,
          2,
          11,
          4,
          7,
          4,
          13,
          2,
          2,
          4,
          1,
          14,
          1,
          8,
          4,
          10,
          2,
          2,
          5,
          5,
          15,
          7,
          4,
          2,
          2,
          1,
          9,
          3,
          5,
          15,
          5,
          8,
          6,
          5,
          2,
          1,
          4,
          2,
          1,
          1,
          1,
          10,
          2,
          19,
          11,
          3,
          7,
          4,
          7,
          4,
          5,
          6,
          12,
          6,
          6,
          4,
          1,
          4,
          6,
          10,
          1,
          6,
          2,
          8,
          7,
          8,
          7,
          2,
          2,
          1,
          2,
          1,
          4,
          8,
          6,
          2,
          7,
          9,
          2,
          8,
          6,
          1,
          17,
          1,
          1,
          1,
          1,
          3,
          9,
          8,
          8,
          5,
          13,
          3,
          2,
          1,
          5,
          1,
          4,
          4,
          1,
          1,
          1,
          1,
          8,
          11,
          6,
          6,
          9,
          16,
          14,
          17,
          8,
          4,
          2,
          3,
          5,
          3,
          3,
          2,
          1,
          2,
          4,
          9,
          3,
          11,
          9,
          4,
          2,
          11,
          4,
          4,
          2,
          3,
          1,
          1,
          1,
          6,
          7,
          15,
          5,
          7,
          5,
          5,
          14,
          1,
          17,
          2,
          7,
          5,
          3,
          1,
          10,
          14,
          5,
          4,
          4,
          4,
          3,
          1,
          7,
          6,
          9,
          14,
          4,
          2,
          3,
          1,
          1,
          10,
          5,
          9,
          7,
          2,
          2,
          4,
          9,
          1,
          13,
          2,
          1,
          13,
          6,
          3,
          2,
          5,
          10,
          11,
          12,
          1,
          17,
          7,
          6,
          9,
          1,
          4,
          7,
          5,
          1,
          1,
          2,
          5,
          6,
          6,
          6,
          2,
          3,
          1,
          9,
          6,
          9,
          5,
          4,
          7,
          4,
          7,
          11,
          20,
          4,
          18,
          16,
          8,
          14,
          4,
          11,
          7,
          16,
          2,
          2,
          2,
          3,
          5,
          4,
          4,
          14,
          4,
          4,
          5,
          10,
          6,
          11,
          9,
          11,
          2,
          2,
          2,
          1
         ]
        }
       ],
       "layout": {
        "barmode": "overlay",
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "#4D5663"
         },
         "text": "Review Text Word Count Distribution"
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "linecolor": "black",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": "word count"
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "linecolor": "black",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": "count"
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"908a5fad-39e8-4a92-ba2b-f66e5de1ba18\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"908a5fad-39e8-4a92-ba2b-f66e5de1ba18\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '908a5fad-39e8-4a92-ba2b-f66e5de1ba18',\n",
       "                        [{\"histfunc\": \"count\", \"histnorm\": \"\", \"marker\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"line\": {\"color\": \"#000000\", \"width\": 1.3}}, \"name\": \"word_count\", \"nbinsx\": 100, \"opacity\": 0.8, \"orientation\": \"v\", \"type\": \"histogram\", \"x\": [9, 8, 8, 7, 7, 3, 6, 2, 16, 19, 5, 8, 8, 2, 2, 2, 5, 14, 11, 8, 7, 10, 7, 4, 4, 9, 7, 5, 13, 1, 2, 4, 7, 18, 17, 9, 6, 4, 18, 2, 11, 4, 7, 4, 5, 1, 3, 3, 2, 10, 6, 7, 8, 12, 2, 7, 19, 8, 14, 5, 5, 7, 8, 6, 8, 4, 4, 8, 2, 10, 5, 3, 8, 2, 1, 6, 14, 1, 16, 1, 11, 9, 8, 7, 7, 3, 11, 7, 12, 1, 2, 2, 2, 2, 2, 2, 2, 5, 11, 10, 1, 7, 2, 10, 8, 5, 8, 2, 5, 11, 2, 7, 1, 10, 1, 1, 7, 3, 3, 1, 2, 4, 4, 2, 7, 4, 7, 2, 3, 6, 14, 3, 4, 5, 4, 2, 11, 2, 14, 3, 6, 11, 10, 7, 4, 15, 10, 4, 4, 12, 4, 4, 9, 6, 15, 3, 2, 3, 4, 1, 8, 5, 3, 5, 22, 5, 3, 5, 9, 1, 1, 1, 2, 1, 4, 12, 3, 4, 19, 21, 16, 7, 5, 5, 10, 6, 10, 14, 14, 3, 3, 3, 13, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 11, 2, 3, 2, 10, 6, 3, 3, 2, 7, 2, 2, 4, 4, 3, 1, 1, 4, 5, 2, 7, 3, 3, 6, 1, 3, 13, 7, 7, 7, 2, 2, 4, 12, 5, 1, 1, 2, 8, 4, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8, 3, 3, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8, 4, 10, 1, 7, 5, 7, 7, 4, 4, 13, 8, 19, 2, 10, 5, 3, 2, 2, 2, 3, 6, 10, 2, 2, 4, 5, 2, 2, 10, 7, 11, 2, 1, 7, 2, 18, 2, 12, 5, 2, 1, 8, 10, 15, 2, 12, 2, 5, 5, 2, 6, 1, 10, 11, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 12, 1, 7, 13, 2, 6, 13, 1, 6, 5, 2, 16, 4, 13, 6, 1, 3, 3, 11, 5, 15, 3, 3, 6, 9, 5, 7, 1, 1, 1, 5, 2, 8, 2, 8, 17, 2, 8, 16, 1, 4, 5, 4, 2, 12, 4, 2, 9, 3, 3, 17, 10, 2, 4, 11, 10, 6, 7, 11, 2, 1, 5, 2, 12, 5, 10, 15, 1, 1, 8, 8, 8, 8, 6, 1, 10, 3, 3, 3, 3, 3, 3, 3, 3, 13, 15, 11, 1, 2, 1, 1, 1, 3, 14, 4, 4, 4, 7, 3, 7, 5, 8, 19, 13, 3, 7, 6, 2, 4, 2, 5, 4, 4, 20, 4, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 4, 4, 7, 19, 6, 4, 8, 11, 3, 3, 2, 2, 2, 2, 7, 7, 7, 7, 7, 7, 6, 7, 7, 7, 7, 7, 7, 7, 5, 7, 2, 13, 9, 2, 14, 5, 4, 1, 2, 8, 13, 4, 13, 11, 8, 1, 5, 7, 5, 3, 7, 4, 3, 3, 5, 1, 1, 22, 5, 3, 3, 3, 3, 7, 2, 9, 6, 4, 8, 8, 4, 5, 8, 15, 8, 15, 8, 8, 15, 2, 8, 15, 8, 4, 7, 10, 4, 13, 1, 13, 9, 2, 3, 17, 8, 13, 2, 12, 5, 3, 7, 7, 6, 7, 2, 3, 1, 6, 18, 3, 1, 1, 4, 1, 1, 17, 14, 19, 4, 21, 4, 8, 10, 5, 1, 1, 4, 3, 9, 2, 8, 2, 8, 2, 8, 1, 2, 8, 1, 2, 3, 4, 4, 3, 7, 15, 7, 3, 5, 7, 10, 8, 3, 5, 7, 6, 5, 6, 5, 5, 14, 2, 4, 1, 8, 10, 11, 15, 18, 12, 15, 5, 5, 2, 9, 7, 5, 5, 5, 5, 4, 11, 2, 7, 4, 4, 11, 9, 1, 4, 4, 1, 2, 5, 2, 4, 1, 9, 16, 3, 5, 2, 3, 2, 5, 3, 10, 1, 8, 9, 6, 3, 4, 4, 1, 6, 10, 9, 4, 6, 7, 4, 2, 9, 11, 5, 5, 12, 4, 4, 11, 1, 4, 2, 8, 1, 4, 1, 3, 1, 9, 3, 13, 6, 2, 5, 3, 3, 3, 3, 2, 1, 12, 3, 7, 1, 2, 3, 3, 1, 9, 1, 11, 1, 13, 15, 6, 1, 1, 5, 1, 1, 1, 3, 8, 10, 10, 5, 5, 7, 1, 5, 1, 1, 8, 8, 5, 6, 7, 7, 7, 7, 7, 7, 7, 12, 3, 1, 12, 3, 4, 6, 5, 6, 4, 14, 6, 17, 4, 4, 4, 4, 8, 8, 7, 6, 5, 5, 4, 10, 5, 9, 1, 12, 5, 9, 3, 2, 1, 15, 2, 7, 2, 2, 9, 1, 4, 9, 1, 6, 7, 7, 1, 4, 2, 8, 5, 8, 3, 2, 2, 2, 2, 10, 10, 16, 2, 2, 6, 2, 1, 6, 4, 8, 6, 12, 7, 5, 1, 1, 2, 2, 3, 1, 1, 2, 2, 8, 2, 9, 10, 9, 10, 8, 2, 2, 2, 2, 2, 2, 2, 2, 6, 5, 6, 1, 5, 5, 2, 3, 4, 2, 2, 2, 2, 8, 9, 3, 10, 1, 4, 8, 8, 8, 1, 1, 15, 2, 2, 6, 4, 16, 1, 1, 1, 3, 1, 2, 8, 1, 8, 4, 11, 4, 10, 3, 1, 2, 2, 2, 2, 4, 5, 10, 9, 5, 4, 2, 7, 4, 3, 1, 3, 1, 3, 1, 9, 3, 7, 2, 6, 2, 2, 4, 2, 5, 2, 9, 3, 1, 9, 10, 8, 9, 4, 5, 14, 9, 3, 2, 2, 2, 6, 2, 2, 2, 4, 1, 1, 1, 3, 3, 1, 11, 4, 4, 10, 18, 4, 6, 10, 5, 5, 3, 16, 2, 12, 7, 3, 3, 6, 4, 9, 3, 17, 8, 7, 3, 2, 15, 14, 11, 7, 5, 1, 2, 2, 2, 2, 12, 9, 4, 2, 12, 3, 1, 1, 1, 1, 1, 3, 11, 2, 10, 4, 3, 9, 17, 3, 9, 6, 2, 6, 3, 6, 11, 6, 6, 1, 12, 12, 12, 12, 3, 4, 4, 9, 9, 13, 5, 12, 6, 4, 4, 8, 4, 11, 9, 16, 10, 8, 5, 8, 7, 5, 1, 15, 4, 3, 1, 1, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 4, 4, 2, 4, 2, 2, 2, 2, 2, 6, 6, 9, 3, 2, 2, 2, 1, 20, 12, 5, 2, 1, 1, 4, 14, 9, 12, 3, 5, 9, 3, 2, 1, 13, 6, 14, 4, 6, 8, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 11, 14, 16, 1, 1, 5, 2, 2, 2, 2, 2, 2, 6, 2, 2, 2, 2, 2, 12, 5, 5, 8, 2, 3, 3, 3, 5, 9, 5, 5, 13, 5, 7, 1, 9, 1, 13, 3, 8, 1, 2, 2, 2, 2, 2, 9, 5, 4, 7, 8, 9, 11, 8, 6, 1, 12, 15, 18, 12, 15, 18, 12, 18, 6, 1, 4, 2, 1, 4, 1, 1, 18, 9, 4, 8, 8, 8, 8, 8, 8, 10, 1, 5, 8, 3, 2, 1, 1, 1, 5, 8, 8, 4, 20, 1, 1, 2, 1, 1, 8, 6, 2, 7, 1, 1, 1, 4, 1, 4, 2, 17, 9, 9, 6, 3, 10, 4, 10, 9, 4, 4, 4, 12, 4, 1, 10, 1, 7, 3, 3, 4, 8, 4, 2, 5, 5, 1, 3, 9, 15, 15, 12, 16, 5, 4, 1, 5, 2, 7, 7, 6, 3, 3, 4, 4, 4, 5, 11, 4, 16, 4, 6, 1, 6, 3, 16, 1, 10, 1, 2, 5, 3, 4, 6, 5, 8, 8, 3, 3, 3, 7, 7, 3, 3, 5, 3, 11, 8, 5, 6, 2, 13, 13, 3, 3, 10, 1, 1, 16, 8, 8, 2, 7, 15, 6, 11, 7, 11, 4, 4, 7, 18, 2, 3, 1, 2, 7, 6, 3, 9, 3, 4, 9, 6, 4, 5, 13, 4, 14, 3, 6, 2, 8, 16, 2, 7, 5, 10, 6, 6, 9, 2, 13, 1, 4, 14, 1, 4, 2, 17, 1, 10, 14, 2, 9, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 6, 18, 18, 10, 7, 18, 18, 10, 10, 10, 10, 10, 10, 2, 4, 4, 6, 5, 7, 6, 5, 12, 6, 2, 11, 4, 12, 3, 14, 15, 2, 2, 2, 1, 4, 10, 8, 1, 4, 6, 15, 1, 2, 5, 20, 13, 1, 1, 4, 1, 16, 14, 14, 6, 17, 7, 9, 8, 5, 2, 2, 6, 6, 6, 6, 7, 4, 2, 16, 1, 2, 2, 4, 9, 6, 7, 1, 6, 6, 7, 5, 1, 10, 4, 4, 3, 5, 4, 3, 5, 12, 5, 10, 14, 5, 6, 6, 3, 4, 8, 4, 6, 4, 12, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 11, 10, 4, 3, 7, 4, 4, 14, 15, 3, 3, 3, 3, 3, 3, 7, 7, 3, 2, 3, 4, 4, 7, 3, 3, 8, 2, 3, 9, 3, 11, 6, 8, 7, 4, 4, 4, 8, 9, 1, 8, 4, 6, 3, 7, 5, 1, 13, 2, 9, 2, 2, 1, 3, 3, 2, 9, 1, 1, 4, 2, 4, 1, 7, 8, 7, 5, 5, 10, 3, 10, 10, 5, 7, 9, 4, 10, 2, 2, 4, 6, 7, 7, 7, 5, 10, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 19, 10, 11, 1, 16, 1, 6, 9, 4, 1, 3, 3, 3, 3, 17, 8, 4, 3, 4, 2, 7, 2, 2, 3, 2, 3, 2, 3, 14, 3, 8, 2, 9, 3, 4, 5, 5, 5, 5, 6, 4, 4, 9, 1, 11, 4, 3, 8, 8, 15, 2, 2, 11, 6, 4, 18, 1, 6, 14, 3, 2, 9, 7, 4, 2, 10, 8, 9, 9, 8, 9, 10, 1, 8, 2, 4, 5, 2, 5, 5, 1, 1, 9, 12, 6, 3, 9, 2, 12, 10, 2, 1, 4, 3, 3, 3, 3, 3, 19, 10, 2, 4, 2, 2, 4, 10, 1, 1, 2, 18, 2, 2, 4, 9, 6, 4, 3, 6, 6, 6, 9, 6, 3, 3, 2, 4, 4, 2, 1, 3, 2, 4, 2, 3, 5, 2, 6, 4, 3, 4, 7, 3, 9, 2, 10, 6, 4, 7, 6, 11, 5, 1, 1, 11, 3, 4, 10, 19, 4, 8, 2, 11, 4, 10, 16, 6, 6, 2, 2, 2, 3, 2, 2, 19, 2, 7, 7, 2, 2, 11, 9, 2, 3, 4, 4, 6, 2, 6, 2, 2, 2, 12, 9, 2, 5, 2, 3, 15, 2, 5, 8, 6, 6, 8, 3, 3, 6, 1, 6, 13, 4, 4, 2, 20, 5, 5, 5, 17, 1, 2, 2, 2, 2, 1, 10, 4, 6, 5, 7, 9, 6, 4, 10, 3, 5, 3, 1, 5, 2, 5, 7, 4, 2, 5, 5, 4, 8, 1, 2, 15, 15, 8, 11, 1, 11, 11, 11, 5, 6, 11, 11, 5, 6, 9, 2, 6, 9, 1, 1, 1, 7, 7, 13, 1, 9, 2, 5, 5, 5, 5, 3, 9, 2, 7, 7, 2, 4, 2, 2, 6, 1, 2, 6, 6, 1, 2, 3, 10, 2, 3, 2, 3, 2, 2, 2, 2, 3, 2, 13, 3, 5, 5, 1, 1, 8, 8, 8, 8, 16, 6, 2, 15, 10, 4, 8, 3, 2, 1, 7, 2, 7, 6, 3, 1, 8, 4, 5, 2, 3, 9, 3, 6, 8, 5, 1, 1, 1, 5, 5, 2, 7, 1, 2, 11, 4, 2, 2, 5, 3, 2, 12, 2, 4, 5, 3, 7, 18, 9, 4, 2, 7, 13, 20, 6, 6, 3, 5, 11, 2, 14, 14, 6, 3, 4, 9, 5, 5, 4, 8, 1, 5, 6, 2, 9, 5, 6, 5, 2, 1, 1, 12, 2, 5, 7, 5, 11, 6, 2, 3, 2, 5, 1, 2, 2, 2, 2, 6, 6, 6, 1, 3, 1, 8, 12, 5, 5, 5, 15, 8, 1, 4, 4, 1, 4, 1, 5, 2, 11, 2, 14, 11, 12, 3, 13, 10, 2, 1, 3, 7, 4, 2, 11, 5, 2, 8, 2, 2, 6, 6, 2, 2, 4, 11, 5, 11, 7, 5, 7, 5, 5, 1, 1, 4, 7, 6, 4, 4, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 4, 2, 2, 2, 2, 2, 2, 2, 7, 14, 4, 12, 5, 9, 3, 12, 5, 2, 1, 3, 3, 2, 6, 15, 6, 9, 21, 13, 2, 3, 3, 2, 3, 6, 11, 8, 11, 5, 6, 10, 1, 2, 2, 7, 1, 8, 1, 1, 7, 8, 2, 1, 2, 2, 4, 17, 16, 5, 3, 1, 3, 7, 2, 10, 1, 6, 3, 3, 13, 2, 4, 3, 11, 7, 8, 8, 3, 13, 5, 5, 14, 11, 3, 4, 10, 2, 3, 1, 1, 14, 14, 13, 4, 5, 5, 16, 10, 3, 5, 3, 10, 1, 6, 5, 15, 10, 6, 11, 2, 2, 2, 3, 4, 2, 10, 4, 3, 9, 1, 11, 13, 13, 3, 2, 1, 14, 18, 9, 4, 5, 3, 14, 8, 2, 8, 2, 2, 4, 2, 15, 7, 3, 7, 18, 6, 6, 6, 7, 8, 9, 6, 4, 1, 1, 6, 10, 1, 4, 3, 7, 12, 7, 5, 1, 7, 3, 14, 9, 1, 1, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 4, 2, 24, 6, 11, 2, 2, 2, 2, 2, 2, 2, 2, 3, 7, 5, 11, 4, 4, 7, 2, 5, 5, 2, 16, 2, 14, 2, 13, 6, 4, 3, 3, 7, 5, 4, 3, 2, 2, 2, 4, 5, 5, 5, 5, 5, 5, 2, 2, 5, 2, 1, 2, 2, 14, 14, 2, 1, 12, 5, 6, 2, 8, 13, 3, 5, 5, 5, 9, 7, 7, 7, 7, 2, 3, 1, 2, 4, 19, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 5, 2, 2, 2, 1, 12, 5, 1, 6, 1, 1, 5, 2, 2, 4, 3, 4, 3, 7, 6, 10, 4, 1, 8, 3, 16, 2, 14, 7, 2, 5, 17, 3, 2, 7, 19, 19, 4, 10, 7, 10, 6, 5, 4, 1, 1, 10, 4, 3, 4, 4, 4, 4, 1, 10, 14, 2, 7, 3, 4, 3, 3, 8, 9, 3, 2, 2, 2, 3, 9, 2, 4, 4, 1, 6, 8, 8, 1, 3, 1, 9, 2, 12, 11, 12, 9, 19, 3, 2, 4, 4, 14, 4, 5, 2, 10, 2, 2, 2, 2, 2, 2, 11, 6, 6, 1, 8, 8, 2, 1, 8, 5, 1, 5, 12, 6, 3, 11, 7, 6, 8, 7, 7, 7, 7, 7, 8, 10, 1, 1, 3, 1, 6, 11, 8, 6, 5, 4, 11, 3, 3, 14, 2, 3, 1, 2, 7, 2, 1, 10, 14, 7, 10, 9, 9, 4, 4, 1, 8, 5, 1, 1, 1, 2, 5, 4, 11, 7, 8, 1, 6, 9, 16, 5, 5, 5, 5, 5, 5, 2, 3, 4, 9, 5, 4, 4, 4, 4, 13, 5, 10, 1, 9, 5, 3, 9, 6, 14, 5, 2, 2, 5, 3, 4, 4, 3, 10, 9, 11, 4, 2, 2, 3, 3, 3, 3, 9, 18, 7, 1, 16, 3, 1, 9, 9, 6, 17, 9, 11, 6, 1, 4, 8, 8, 2, 1, 16, 2, 5, 1, 1, 4, 9, 14, 3, 8, 4, 5, 2, 10, 2, 8, 8, 3, 6, 3, 4, 5, 5, 4, 2, 11, 15, 5, 7, 2, 11, 2, 1, 1, 8, 14, 19, 2, 3, 4, 4, 7, 1, 1, 4, 5, 5, 4, 8, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 4, 5, 5, 9, 8, 9, 5, 2, 8, 5, 12, 9, 19, 19, 11, 7, 20, 5, 12, 6, 2, 1, 5, 2, 3, 6, 8, 8, 4, 7, 2, 7, 9, 5, 5, 2, 5, 2, 13, 16, 15, 1, 6, 4, 10, 2, 15, 1, 9, 2, 19, 3, 1, 3, 2, 3, 3, 2, 4, 5, 2, 2, 2, 4, 2, 4, 7, 1, 13, 13, 13, 13, 13, 13, 13, 18, 2, 1, 3, 2, 1, 6, 4, 8, 5, 11, 4, 11, 7, 2, 15, 2, 1, 2, 1, 10, 2, 2, 3, 3, 5, 2, 5, 2, 22, 8, 1, 11, 3, 3, 6, 6, 2, 12, 2, 12, 2, 12, 3, 12, 3, 3, 3, 2, 2, 2, 2, 2, 1, 3, 13, 13, 2, 7, 2, 3, 2, 4, 11, 1, 4, 1, 1, 6, 4, 10, 9, 10, 23, 15, 2, 12, 3, 7, 12, 13, 5, 6, 7, 4, 3, 15, 3, 7, 1, 2, 1, 7, 11, 1, 12, 16, 2, 2, 2, 2, 16, 4, 15, 14, 12, 4, 13, 5, 1, 1, 3, 1, 3, 1, 1, 5, 11, 1, 1, 3, 3, 6, 2, 10, 8, 21, 12, 6, 5, 2, 4, 5, 4, 2, 4, 5, 9, 4, 4, 1, 2, 2, 2, 4, 1, 1, 7, 4, 12, 2, 2, 2, 2, 10, 1, 2, 2, 2, 2, 7, 7, 7, 7, 7, 4, 7, 7, 2, 7, 7, 7, 3, 7, 2, 7, 1, 5, 5, 8, 2, 3, 5, 7, 17, 4, 3, 2, 2, 9, 7, 7, 5, 18, 3, 6, 12, 3, 14, 2, 7, 3, 3, 1, 5, 5, 5, 3, 11, 13, 2, 4, 9, 1, 4, 2, 4, 3, 5, 4, 10, 7, 13, 4, 14, 2, 2, 11, 5, 5, 6, 5, 1, 2, 19, 5, 4, 7, 11, 3, 4, 9, 5, 3, 6, 3, 5, 9, 8, 2, 2, 2, 8, 7, 7, 1, 5, 2, 2, 2, 4, 13, 11, 1, 13, 2, 11, 10, 20, 9, 2, 12, 8, 9, 1, 7, 8, 8, 11, 2, 7, 3, 8, 3, 6, 10, 2, 7, 7, 6, 1, 4, 1, 1, 3, 10, 4, 4, 4, 4, 3, 3, 6, 2, 2, 4, 11, 4, 2, 4, 2, 6, 1, 2, 2, 1, 2, 2, 11, 8, 8, 5, 7, 10, 13, 10, 13, 6, 4, 5, 6, 19, 17, 15, 3, 3, 9, 2, 2, 3, 1, 6, 10, 16, 10, 6, 1, 1, 7, 11, 18, 7, 1, 9, 9, 1, 5, 9, 3, 9, 3, 1, 3, 4, 4, 18, 4, 4, 2, 10, 10, 1, 13, 3, 3, 12, 2, 2, 2, 5, 5, 5, 6, 11, 3, 9, 16, 20, 6, 18, 3, 3, 8, 8, 4, 17, 8, 11, 16, 2, 2, 14, 6, 6, 2, 2, 2, 11, 4, 7, 4, 13, 2, 2, 4, 1, 14, 1, 8, 4, 10, 2, 2, 5, 5, 15, 7, 4, 2, 2, 1, 9, 3, 5, 15, 5, 8, 6, 5, 2, 1, 4, 2, 1, 1, 1, 10, 2, 19, 11, 3, 7, 4, 7, 4, 5, 6, 12, 6, 6, 4, 1, 4, 6, 10, 1, 6, 2, 8, 7, 8, 7, 2, 2, 1, 2, 1, 4, 8, 6, 2, 7, 9, 2, 8, 6, 1, 17, 1, 1, 1, 1, 3, 9, 8, 8, 5, 13, 3, 2, 1, 5, 1, 4, 4, 1, 1, 1, 1, 8, 11, 6, 6, 9, 16, 14, 17, 8, 4, 2, 3, 5, 3, 3, 2, 1, 2, 4, 9, 3, 11, 9, 4, 2, 11, 4, 4, 2, 3, 1, 1, 1, 6, 7, 15, 5, 7, 5, 5, 14, 1, 17, 2, 7, 5, 3, 1, 10, 14, 5, 4, 4, 4, 3, 1, 7, 6, 9, 14, 4, 2, 3, 1, 1, 10, 5, 9, 7, 2, 2, 4, 9, 1, 13, 2, 1, 13, 6, 3, 2, 5, 10, 11, 12, 1, 17, 7, 6, 9, 1, 4, 7, 5, 1, 1, 2, 5, 6, 6, 6, 2, 3, 1, 9, 6, 9, 5, 4, 7, 4, 7, 11, 20, 4, 18, 16, 8, 14, 4, 11, 7, 16, 2, 2, 2, 3, 5, 4, 4, 14, 4, 4, 5, 10, 6, 11, 9, 11, 2, 2, 2, 1]}],\n",
       "                        {\"barmode\": \"overlay\", \"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"Review Text Word Count Distribution\"}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"linecolor\": \"black\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"word count\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"linecolor\": \"black\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"count\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('908a5fad-39e8-4a92-ba2b-f66e5de1ba18');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['word_count'].iplot(\n",
    "    kind='hist',\n",
    "    bins=100,\n",
    "    xTitle='word count',\n",
    "    linecolor='black',\n",
    "    yTitle='count',\n",
    "    title='Review Text Word Count Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chimney 1174\n",
      "damage 509\n",
      "structure 399\n",
      "good 345\n",
      "cracks 344\n",
      "wall 267\n",
      "minor 241\n",
      "cracking 225\n",
      "roof 213\n",
      "comments 194\n",
      "cracked 193\n",
      "foundation 175\n",
      "area 162\n",
      "use 159\n",
      "tag 150\n",
      "green 150\n",
      "interior 148\n",
      "exterior 145\n",
      "damaged 139\n",
      "stucco 138\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "marker": {
          "color": "rgba(255, 153, 51, 0.6)",
          "line": {
           "color": "rgba(255, 153, 51, 1.0)",
           "width": 1
          }
         },
         "name": "count",
         "orientation": "v",
         "text": "",
         "type": "bar",
         "x": [
          "chimney",
          "damage",
          "structure",
          "good",
          "cracks",
          "wall",
          "minor",
          "cracking",
          "roof",
          "comments",
          "cracked",
          "foundation",
          "area",
          "use",
          "green",
          "tag",
          "interior",
          "exterior",
          "damaged",
          "stucco"
         ],
         "y": [
          1174,
          509,
          399,
          345,
          344,
          267,
          241,
          225,
          213,
          194,
          193,
          175,
          162,
          159,
          150,
          150,
          148,
          145,
          139,
          138
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "#4D5663"
         },
         "text": "Top 20 words in review after removing stop words"
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "linecolor": "black",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "linecolor": "black",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": "Count"
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"f98f7c91-e180-4203-a3e7-870aed24e08e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"f98f7c91-e180-4203-a3e7-870aed24e08e\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'f98f7c91-e180-4203-a3e7-870aed24e08e',\n",
       "                        [{\"marker\": {\"color\": \"rgba(255, 153, 51, 0.6)\", \"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"width\": 1}}, \"name\": \"count\", \"orientation\": \"v\", \"text\": \"\", \"type\": \"bar\", \"x\": [\"chimney\", \"damage\", \"structure\", \"good\", \"cracks\", \"wall\", \"minor\", \"cracking\", \"roof\", \"comments\", \"cracked\", \"foundation\", \"area\", \"use\", \"green\", \"tag\", \"interior\", \"exterior\", \"damaged\", \"stucco\"], \"y\": [1174, 509, 399, 345, 344, 267, 241, 225, 213, 194, 193, 175, 162, 159, 150, 150, 148, 145, 139, 138]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"Top 20 words in review after removing stop words\"}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"linecolor\": \"black\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"linecolor\": \"black\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"Count\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f98f7c91-e180-4203-a3e7-870aed24e08e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(data['texts'], 20)\n",
    "for word, freq in common_words:\n",
    "    print(word, freq)\n",
    "df2 = pd.DataFrame(common_words, columns = ['texts' , 'count'])\n",
    "df2.groupby('texts').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', yTitle='Count', linecolor='black', title='Top 20 words in review after removing stop words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structure good 330\n",
      "green tag 92\n",
      "stay clear 77\n",
      "roof line 54\n",
      "use fireplace 53\n",
      "chimney damage 53\n",
      "chimney cracked 52\n",
      "structural damage 49\n",
      "ok occupy 49\n",
      "damaged chimney 49\n",
      "minor cracks 48\n",
      "falling hazard 48\n",
      "chimney fell 47\n",
      "chimney area 45\n",
      "cracked chimney 44\n",
      "clear chimney 44\n",
      "stucco cracking 43\n",
      "moderate damage 40\n",
      "damage limited 39\n",
      "bel aire 38\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "marker": {
          "color": "rgba(255, 153, 51, 0.6)",
          "line": {
           "color": "rgba(255, 153, 51, 1.0)",
           "width": 1
          }
         },
         "name": "count",
         "orientation": "v",
         "text": "",
         "type": "bar",
         "x": [
          "structure good",
          "green tag",
          "stay clear",
          "roof line",
          "use fireplace",
          "chimney damage",
          "chimney cracked",
          "damaged chimney",
          "structural damage",
          "ok occupy",
          "falling hazard",
          "minor cracks",
          "chimney fell",
          "chimney area",
          "cracked chimney",
          "clear chimney",
          "stucco cracking",
          "moderate damage",
          "damage limited",
          "bel aire"
         ],
         "y": [
          330,
          92,
          77,
          54,
          53,
          53,
          52,
          49,
          49,
          49,
          48,
          48,
          47,
          45,
          44,
          44,
          43,
          40,
          39,
          38
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "#4D5663"
         },
         "text": "Top 20 bigrams in review after removing stop words"
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "linecolor": "black",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "linecolor": "black",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": "Count"
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"9317b36d-41a5-4d24-aa93-3c2dd6b099c3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"9317b36d-41a5-4d24-aa93-3c2dd6b099c3\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '9317b36d-41a5-4d24-aa93-3c2dd6b099c3',\n",
       "                        [{\"marker\": {\"color\": \"rgba(255, 153, 51, 0.6)\", \"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"width\": 1}}, \"name\": \"count\", \"orientation\": \"v\", \"text\": \"\", \"type\": \"bar\", \"x\": [\"structure good\", \"green tag\", \"stay clear\", \"roof line\", \"use fireplace\", \"chimney damage\", \"chimney cracked\", \"damaged chimney\", \"structural damage\", \"ok occupy\", \"falling hazard\", \"minor cracks\", \"chimney fell\", \"chimney area\", \"cracked chimney\", \"clear chimney\", \"stucco cracking\", \"moderate damage\", \"damage limited\", \"bel aire\"], \"y\": [330, 92, 77, 54, 53, 53, 52, 49, 49, 49, 48, 48, 47, 45, 44, 44, 43, 40, 39, 38]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"Top 20 bigrams in review after removing stop words\"}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"linecolor\": \"black\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"linecolor\": \"black\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"Count\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('9317b36d-41a5-4d24-aa93-3c2dd6b099c3');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_top_n_bigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_bigram(data['texts'], 20)\n",
    "for word, freq in common_words:\n",
    "    print(word, freq)\n",
    "df4 = pd.DataFrame(common_words, columns = ['texts' , 'count'])\n",
    "df4.groupby('texts').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', yTitle='Count', linecolor='black', title='Top 20 bigrams in review after removing stop words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = data.loc[data['labels'] == 'Red']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>texts</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>noticable damages observed exterior chimney da...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Green</td>\n",
       "      <td>cracks wood ridge beam appear ordinary shrinka...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Green</td>\n",
       "      <td>cracks gypbd roof beam porch interior beam twi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Green</td>\n",
       "      <td>minor cracks chimney home appears safe secure</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>use front porch except enter exit home</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                              texts  word_count\n",
       "0  Yellow  noticable damages observed exterior chimney da...           9\n",
       "1   Green  cracks wood ridge beam appear ordinary shrinka...           8\n",
       "2   Green  cracks gypbd roof beam porch interior beam twi...           8\n",
       "3   Green      minor cracks chimney home appears safe secure           7\n",
       "4  Yellow             use front porch except enter exit home           7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.texts\n",
    "y = data.labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps includes feature engineering. We will convert our text documents to a matrix of token counts (CountVectorizer), then transform a count matrix to a normalized tf-idf representation (tf-idf transformer). After that, we train several classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier for multinomial models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.8140214216163584\n",
      "[[361 105   0]\n",
      " [ 32 469   0]\n",
      " [  6  48   6]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.8860601001669449\n",
      "[[ 977  109    0]\n",
      " [  35 1138    0]\n",
      " [  17  112    8]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.90      0.77      0.83       466\n",
      "      Yellow       1.00      0.10      0.18        60\n",
      "         Red       0.75      0.94      0.84       501\n",
      "\n",
      "    accuracy                           0.81      1027\n",
      "   macro avg       0.89      0.60      0.62      1027\n",
      "weighted avg       0.84      0.81      0.80      1027\n",
      "\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "y_pred_train = nb.predict(X_train)\n",
    "\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=5, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=42,\n",
       "                               shuffle=True, tol=None, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.8442064264849075\n",
      "[[390  76   0]\n",
      " [ 43 457   1]\n",
      " [  3  37  20]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.9307178631051753\n",
      "[[1020   66    0]\n",
      " [  29 1142    2]\n",
      " [  11   58   68]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.89      0.84      0.86       466\n",
      "      Yellow       0.95      0.33      0.49        60\n",
      "         Red       0.80      0.91      0.85       501\n",
      "\n",
      "    accuracy                           0.84      1027\n",
      "   macro avg       0.88      0.69      0.74      1027\n",
      "weighted avg       0.85      0.84      0.84      1027\n",
      "\n",
      "Wall time: 83.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = sgd.predict(X_test)\n",
    "y_pred_train = sgd.predict(X_train)\n",
    "\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "C:\\Users\\sujit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning:\n",
      "\n",
      "Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=1, penalty='l2',\n",
       "                                    random_state=None, solver='warn',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.810126582278481\n",
      "[[369  75  22]\n",
      " [ 52 429  20]\n",
      " [  2  24  34]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.996661101836394\n",
      "[[1083    2    1]\n",
      " [   1 1172    0]\n",
      " [   0    4  133]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.87      0.79      0.83       466\n",
      "      Yellow       0.45      0.57      0.50        60\n",
      "         Red       0.81      0.86      0.83       501\n",
      "\n",
      "    accuracy                           0.81      1027\n",
      "   macro avg       0.71      0.74      0.72      1027\n",
      "weighted avg       0.82      0.81      0.81      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_pred_train = logreg.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 DecisionTreeClassifier(class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features=None,\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort=False, random_state=0,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', DecisionTreeClassifier(random_state=0)),\n",
    "               ])\n",
    "DT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.824732229795521\n",
      "[[386  73   7]\n",
      " [ 53 429  19]\n",
      " [  4  24  32]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.9970784641068448\n",
      "[[1085    1    0]\n",
      " [   1 1170    2]\n",
      " [   1    2  134]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.87      0.83      0.85       466\n",
      "      Yellow       0.55      0.53      0.54        60\n",
      "         Red       0.82      0.86      0.84       501\n",
      "\n",
      "    accuracy                           0.82      1027\n",
      "   macro avg       0.75      0.74      0.74      1027\n",
      "weighted avg       0.83      0.82      0.82      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = DT.predict(X_test)\n",
    "y_pred_train = DT.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=200, n_jobs=None,\n",
       "                                        oob_score=False, random_state=0,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', RandomForestClassifier(n_estimators=200,  random_state=0)),\n",
    "               ])\n",
    "RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.8558909444985394\n",
      "[[395  67   4]\n",
      " [ 40 456   5]\n",
      " [  5  27  28]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.9970784641068448\n",
      "[[1085    1    0]\n",
      " [   1 1171    1]\n",
      " [   1    3  133]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.90      0.85      0.87       466\n",
      "      Yellow       0.76      0.47      0.58        60\n",
      "         Red       0.83      0.91      0.87       501\n",
      "\n",
      "    accuracy                           0.86      1027\n",
      "   macro avg       0.83      0.74      0.77      1027\n",
      "weighted avg       0.86      0.86      0.85      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = RF.predict(X_test)\n",
    "y_pred_train = RF.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "                                    learning_rate=1.0, n_estimators=100,\n",
       "                                    random_state=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ADB = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', AdaBoostClassifier(n_estimators=100, random_state=0)),\n",
    "               ])\n",
    "ADB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.7867575462512172\n",
      "[[402  62   2]\n",
      " [106 381  14]\n",
      " [  7  28  25]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.8251252086811353\n",
      "[[993  91   2]\n",
      " [234 912  27]\n",
      " [  9  56  72]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.78      0.86      0.82       466\n",
      "      Yellow       0.61      0.42      0.50        60\n",
      "         Red       0.81      0.76      0.78       501\n",
      "\n",
      "    accuracy                           0.79      1027\n",
      "   macro avg       0.73      0.68      0.70      1027\n",
      "weighted avg       0.78      0.79      0.78      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ADB.predict(X_test)\n",
    "y_pred_train = ADB.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=3,\n",
       "                               min_child_weight=1, missing=None,\n",
       "                               n_estimators=100, n_jobs=1, nthread=None,\n",
       "                               objective='multi:softprob', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=None, subsample=1,\n",
       "                               verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "XGB = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', XGBClassifier()),\n",
    "               ])\n",
    "XGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.8286270691333982\n",
      "[[402  64   0]\n",
      " [ 67 429   5]\n",
      " [ 14  26  20]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.8843906510851419\n",
      "[[1022   63    1]\n",
      " [ 137 1032    4]\n",
      " [  28   44   65]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.83      0.86      0.85       466\n",
      "      Yellow       0.80      0.33      0.47        60\n",
      "         Red       0.83      0.86      0.84       501\n",
      "\n",
      "    accuracy                           0.83      1027\n",
      "   macro avg       0.82      0.68      0.72      1027\n",
      "weighted avg       0.83      0.83      0.82      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = XGB.predict(X_test)\n",
    "y_pred_train = XGB.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                colsample_bytree=1.0, importance_type='split',\n",
       "                                learning_rate=0.1, max_depth=-1,\n",
       "                                min_child_samples=20, min_child_weight=0.001,\n",
       "                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n",
       "                                num_leaves=31, objective=None,\n",
       "                                random_state=None, reg_alpha=0.0,\n",
       "                                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                                subsample_for_bin=200000, subsample_freq=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "LGB = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LGBMClassifier()),\n",
    "               ])\n",
    "LGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.8490749756572541\n",
      "[[392  65   9]\n",
      " [ 42 451   8]\n",
      " [  8  23  29]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.9595158597662772\n",
      "[[1066   18    2]\n",
      " [  53 1113    7]\n",
      " [  10    7  120]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.89      0.84      0.86       466\n",
      "      Yellow       0.63      0.48      0.55        60\n",
      "         Red       0.84      0.90      0.87       501\n",
      "\n",
      "    accuracy                           0.85      1027\n",
      "   macro avg       0.78      0.74      0.76      1027\n",
      "weighted avg       0.85      0.85      0.85      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = LGB.predict(X_test)\n",
    "y_pred_train = LGB.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we convert text to vectors using word2vec and do the comparison of various machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning:\n",
      "\n",
      "This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"C:\\\\Users\\\\sujit\\\\Documents\\\\GitHub\\\\Napa_Earthquake_Text_classification\\\\GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "\n",
    "wv.init_sims(replace=True)\n",
    "\n",
    "# from smart_open import open  \n",
    "# import smart_open\n",
    "# smart_open.open('s3://commoncrawl/robots.txt', 'rb').read(32)\n",
    "# b'User-Agent: *\\nDisallow: /'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Memorial_Hospital',\n",
       " 'Seniors',\n",
       " 'memorandum',\n",
       " 'elephant',\n",
       " 'Trump',\n",
       " 'Census',\n",
       " 'pilgrims',\n",
       " 'De',\n",
       " 'Dogs',\n",
       " '###-####_ext',\n",
       " 'chaotic',\n",
       " 'forgive',\n",
       " 'scholar',\n",
       " 'Lottery',\n",
       " 'decreasing',\n",
       " 'Supervisor',\n",
       " 'fundamentally',\n",
       " 'Fitness',\n",
       " 'abundance',\n",
       " 'Hold']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "list(islice(wv.vocab, 13030, 13050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.vectors_norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.3, random_state = 42)\n",
    "\n",
    "test_tokenized = test.apply(lambda r: w2v_tokenize_text(r['texts']), axis=1).values\n",
    "train_tokenized = train.apply(lambda r: w2v_tokenize_text(r['texts']), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute similarity with no input ['angele']\n",
      "WARNING:root:cannot compute similarity with no input ['piners']\n",
      "WARNING:root:cannot compute similarity with no input ['apartmentsinspected']\n",
      "WARNING:root:cannot compute similarity with no input ['safewy']\n",
      "WARNING:root:cannot compute similarity with no input ['yobelle']\n",
      "WARNING:root:cannot compute similarity with no input ['subwy']\n",
      "WARNING:root:cannot compute similarity with no input ['kohls']\n",
      "WARNING:root:cannot compute similarity with no input ['apartmentsinspected']\n",
      "WARNING:root:cannot compute similarity with no input ['formatech']\n",
      "WARNING:root:cannot compute similarity with no input ['apartmentsinspected']\n",
      "WARNING:root:cannot compute similarity with no input ['supercuts']\n",
      "WARNING:root:cannot compute similarity with no input ['pericos']\n",
      "WARNING:root:cannot compute similarity with no input ['fagianis']\n",
      "WARNING:root:cannot compute similarity with no input ['restricitions']\n",
      "WARNING:root:cannot compute similarity with no input ['apartmentsinspected']\n"
     ]
    }
   ],
   "source": [
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "C:\\Users\\sujit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning:\n",
      "\n",
      "Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(X_train_word_average, train['labels'])\n",
    "y_pred = logreg.predict(X_test_word_average)\n",
    "y_pred_train = logreg.predict(X_train_word_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.8257059396299903\n",
      "[[389  64  13]\n",
      " [ 53 422  26]\n",
      " [  5  18  37]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.9620200333889817\n",
      "[[1036   50    0]\n",
      " [  33 1139    1]\n",
      " [   3    4  130]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.87      0.83      0.85       466\n",
      "      Yellow       0.49      0.62      0.54        60\n",
      "         Red       0.84      0.84      0.84       501\n",
      "\n",
      "    accuracy                           0.83      1027\n",
      "   macro avg       0.73      0.76      0.75      1027\n",
      "weighted avg       0.83      0.83      0.83      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of test set %s' % accuracy_score(y_pred, test.labels))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00246594,  0.0521712 , -0.0200479 , ..., -0.04671119,\n",
       "         0.03036719,  0.0008012 ],\n",
       "       [ 0.01803191,  0.07164127, -0.0925671 , ..., -0.04564193,\n",
       "         0.04144321, -0.0265803 ],\n",
       "       [ 0.00033761,  0.04973388, -0.03683099, ..., -0.10000218,\n",
       "        -0.08678242, -0.03184164],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.00806111,  0.05315241, -0.00610028, ..., -0.14680903,\n",
       "         0.02909382, -0.0738406 ],\n",
       "       [ 0.02789648,  0.02310111, -0.04271152, ..., -0.07185823,\n",
       "         0.08289505, -0.07431073]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_word_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# MNB = MultinomialNB()\n",
    "# MNB = MNB.fit(X_train_word_average, train['labels'])\n",
    "# y_pred = MNB.predict(X_test_word_average)\n",
    "# y_pred_train = MNB.predict(X_train_word_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=42, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGD = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "SGD.fit(X_train_word_average, train['labels'])\n",
    "y_pred = SGD.predict(X_test_word_average)\n",
    "y_pred_train = SGD.predict(X_train_word_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.8120740019474196\n",
      "[[357 105   4]\n",
      " [ 32 467   2]\n",
      " [ 10  40  10]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.8626878130217028\n",
      "[[ 913  172    1]\n",
      " [  47 1113   13]\n",
      " [  19   77   41]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.89      0.77      0.83       466\n",
      "      Yellow       0.62      0.17      0.26        60\n",
      "         Red       0.76      0.93      0.84       501\n",
      "\n",
      "    accuracy                           0.81      1027\n",
      "   macro avg       0.76      0.62      0.64      1027\n",
      "weighted avg       0.81      0.81      0.80      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of test set %s' % accuracy_score(y_pred, test.labels))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(X_train_word_average, train['labels'])\n",
    "y_pred = DT.predict(X_test_word_average)\n",
    "y_pred_train = DT.predict(X_train_word_average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.7896786757546251\n",
      "[[371  87   8]\n",
      " [ 56 414  31]\n",
      " [  9  25  26]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.9962437395659433\n",
      "[[1085    1    0]\n",
      " [   2 1169    2]\n",
      " [   2    2  133]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.85      0.80      0.82       466\n",
      "      Yellow       0.40      0.43      0.42        60\n",
      "         Red       0.79      0.83      0.81       501\n",
      "\n",
      "    accuracy                           0.79      1027\n",
      "   macro avg       0.68      0.69      0.68      1027\n",
      "weighted avg       0.79      0.79      0.79      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of test set %s' % accuracy_score(y_pred, test.labels))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF =  RandomForestClassifier(n_estimators=200,  random_state=0)\n",
    "RF.fit(X_train_word_average, train['labels'])\n",
    "y_pred = RF.predict(X_test_word_average)\n",
    "y_pred_train = RF.predict(X_train_word_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.8364167478091529\n",
      "[[369  95   2]\n",
      " [ 30 471   0]\n",
      " [  8  33  19]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.9962437395659433\n",
      "[[1085    1    0]\n",
      " [   2 1171    0]\n",
      " [   2    4  131]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.91      0.79      0.85       466\n",
      "      Yellow       0.90      0.32      0.47        60\n",
      "         Red       0.79      0.94      0.86       501\n",
      "\n",
      "    accuracy                           0.84      1027\n",
      "   macro avg       0.87      0.68      0.72      1027\n",
      "weighted avg       0.85      0.84      0.83      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of test set %s' % accuracy_score(y_pred, test.labels))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ADB = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "ADB.fit(X_train_word_average, train['labels'])\n",
    "y_pred = ADB.predict(X_test_word_average)\n",
    "y_pred_train = ADB.predict(X_train_word_average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.7555988315481986\n",
      "[[345 117   4]\n",
      " [ 90 405   6]\n",
      " [  5  29  26]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.833889816360601\n",
      "[[908 177   1]\n",
      " [166 993  14]\n",
      " [  2  38  97]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.78      0.74      0.76       466\n",
      "      Yellow       0.72      0.43      0.54        60\n",
      "         Red       0.74      0.81      0.77       501\n",
      "\n",
      "    accuracy                           0.76      1027\n",
      "   macro avg       0.75      0.66      0.69      1027\n",
      "weighted avg       0.76      0.76      0.75      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of test set %s' % accuracy_score(y_pred, test.labels))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "XGB =  XGBClassifier()\n",
    "XGB.fit(X_train_word_average, train['labels'])\n",
    "y_pred = XGB.predict(X_test_word_average)\n",
    "y_pred_train = XGB.predict(X_train_word_average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.8432327166504382\n",
      "[[375  89   2]\n",
      " [ 32 468   1]\n",
      " [  6  31  23]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.9753756260434057\n",
      "[[1048   38    0]\n",
      " [   6 1166    1]\n",
      " [   2   12  123]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.91      0.80      0.85       466\n",
      "      Yellow       0.88      0.38      0.53        60\n",
      "         Red       0.80      0.93      0.86       501\n",
      "\n",
      "    accuracy                           0.84      1027\n",
      "   macro avg       0.86      0.71      0.75      1027\n",
      "weighted avg       0.85      0.84      0.84      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of test set %s' % accuracy_score(y_pred, test.labels))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "LGB =  LGBMClassifier()\n",
    "LGB.fit(X_train_word_average, train['labels'])\n",
    "y_pred = LGB.predict(X_test_word_average)\n",
    "y_pred_train = LGB.predict(X_train_word_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.8422590068159689\n",
      "[[381  83   2]\n",
      " [ 32 464   5]\n",
      " [  5  35  20]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.9962437395659433\n",
      "[[1085    1    0]\n",
      " [   2 1170    1]\n",
      " [   2    3  132]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.91      0.82      0.86       466\n",
      "      Yellow       0.74      0.33      0.46        60\n",
      "         Red       0.80      0.93      0.86       501\n",
      "\n",
      "    accuracy                           0.84      1027\n",
      "   macro avg       0.82      0.69      0.73      1027\n",
      "weighted avg       0.85      0.84      0.84      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of test set %s' % accuracy_score(y_pred, test.labels))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(y_pred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2vec, taking the linear combination of every term in the document creates a random walk with bias process in the word2vec space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import doc2vec\n",
    "from sklearn import utils\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(doc2vec.TaggedDocument(v.split(), [label]))\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.texts, data.labels, random_state=0, test_size=0.3)\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['playful', 'gardner'], tags=['Train_1']),\n",
       " TaggedDocument(words=['chimney', 'damage'], tags=['Train_2']),\n",
       " TaggedDocument(words=['structure', 'good'], tags=['Train_3']),\n",
       " TaggedDocument(words=['structure', 'good'], tags=['Train_4'])]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3423/3423 [00:00<00:00, 73327.97it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3423/3423 [00:00<00:00, 995224.08it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1227942.40it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1143718.84it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1257409.58it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1529629.51it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<?, ?it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1909189.17it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1687284.36it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 552281.22it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1591696.52it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1253785.92it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 2049843.32it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1497871.94it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1858043.56it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1353549.79it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 3319561.29it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 2580820.17it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 22053921.03it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 896534.44it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1312589.38it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 2395245.68it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1358802.06it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1665943.68it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1567882.78it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 414501.91it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1194732.68it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 334461.69it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 642577.21it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1601461.53it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "100%|██████████| 3423/3423 [00:00<00:00, 1795760.17it/s]\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "C:\\Users\\sujit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning:\n",
      "\n",
      "Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=1, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(train_vectors_dbow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "C:\\Users\\sujit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning:\n",
      "\n",
      "Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "ypred_train = logreg.predict(train_vectors_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.7974683544303798\n",
      "[[377  72   9]\n",
      " [ 75 409  28]\n",
      " [  2  22  33]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.9115191986644408\n",
      "[[489 537  68]\n",
      " [531 575  56]\n",
      " [ 69  62   9]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.83      0.82      0.83       458\n",
      "      Yellow       0.47      0.58      0.52        57\n",
      "         Red       0.81      0.80      0.81       512\n",
      "\n",
      "    accuracy                           0.80      1027\n",
      "   macro avg       0.70      0.73      0.72      1027\n",
      "weighted avg       0.80      0.80      0.80      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(ypred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Naive Bayes\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# MNB = MultinomialNB()\n",
    "# MNB = MNB.fit(train_vectors_dbow, y_train)\n",
    "# y_pred = MNB.predict(test_vectors_dbow)\n",
    "# ypred_train = MNB.predict(train_vectors_dbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=42, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGD = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "SGD.fit(train_vectors_dbow, y_train)\n",
    "y_pred = SGD.predict(test_vectors_dbow)\n",
    "ypred_train = SGD.predict(train_vectors_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.7497565725413826\n",
      "[[350 108   0]\n",
      " [ 95 416   1]\n",
      " [  7  46   4]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.7662771285475793\n",
      "[[489 537  68]\n",
      " [531 575  56]\n",
      " [ 69  62   9]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.77      0.76      0.77       458\n",
      "      Yellow       0.80      0.07      0.13        57\n",
      "         Red       0.73      0.81      0.77       512\n",
      "\n",
      "    accuracy                           0.75      1027\n",
      "   macro avg       0.77      0.55      0.56      1027\n",
      "weighted avg       0.75      0.75      0.73      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(ypred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(train_vectors_dbow, y_train)\n",
    "y_pred = DT.predict(test_vectors_dbow)\n",
    "ypred_train = DT.predict(train_vectors_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.7526777020447907\n",
      "[[352  87  19]\n",
      " [ 82 398  32]\n",
      " [  9  25  23]]\n",
      "---------------------------\n",
      "Accuracy of training set 1.0\n",
      "[[489 537  68]\n",
      " [531 575  56]\n",
      " [ 69  62   9]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.79      0.77      0.78       458\n",
      "      Yellow       0.31      0.40      0.35        57\n",
      "         Red       0.78      0.78      0.78       512\n",
      "\n",
      "    accuracy                           0.75      1027\n",
      "   macro avg       0.63      0.65      0.64      1027\n",
      "weighted avg       0.76      0.75      0.76      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(ypred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF =  RandomForestClassifier(n_estimators=200,  random_state=0)\n",
    "RF.fit(train_vectors_dbow, y_train)\n",
    "y_pred = RF.predict(test_vectors_dbow)\n",
    "ypred_train = RF.predict(train_vectors_dbow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.8519961051606622\n",
      "[[384  74   0]\n",
      " [ 37 473   2]\n",
      " [  4  35  18]]\n",
      "---------------------------\n",
      "Accuracy of training set 1.0\n",
      "[[489 537  68]\n",
      " [531 575  56]\n",
      " [ 69  62   9]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.90      0.84      0.87       458\n",
      "      Yellow       0.90      0.32      0.47        57\n",
      "         Red       0.81      0.92      0.86       512\n",
      "\n",
      "    accuracy                           0.85      1027\n",
      "   macro avg       0.87      0.69      0.73      1027\n",
      "weighted avg       0.86      0.85      0.84      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(ypred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ADB = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "ADB.fit(train_vectors_dbow, y_train)\n",
    "y_pred = ADB.predict(test_vectors_dbow)\n",
    "ypred_train = ADB.predict(train_vectors_dbow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.8052580331061344\n",
      "[[359  98   1]\n",
      " [ 59 444   9]\n",
      " [  2  31  24]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.8021702838063439\n",
      "[[489 537  68]\n",
      " [531 575  56]\n",
      " [ 69  62   9]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.85      0.78      0.82       458\n",
      "      Yellow       0.71      0.42      0.53        57\n",
      "         Red       0.77      0.87      0.82       512\n",
      "\n",
      "    accuracy                           0.81      1027\n",
      "   macro avg       0.78      0.69      0.72      1027\n",
      "weighted avg       0.81      0.81      0.80      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(ypred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "XGB =  XGBClassifier()\n",
    "XGB.fit(train_vectors_dbow, y_train)\n",
    "y_pred = XGB.predict(test_vectors_dbow)\n",
    "ypred_train = XGB.predict(train_vectors_dbow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.8451801363193768\n",
      "[[391  65   2]\n",
      " [ 48 455   9]\n",
      " [  3  32  22]]\n",
      "---------------------------\n",
      "Accuracy of training set 0.9419866444073456\n",
      "[[489 537  68]\n",
      " [531 575  56]\n",
      " [ 69  62   9]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.88      0.85      0.87       458\n",
      "      Yellow       0.67      0.39      0.49        57\n",
      "         Red       0.82      0.89      0.86       512\n",
      "\n",
      "    accuracy                           0.85      1027\n",
      "   macro avg       0.79      0.71      0.74      1027\n",
      "weighted avg       0.84      0.85      0.84      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(ypred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "LGB =  LGBMClassifier()\n",
    "LGB.fit(train_vectors_dbow, y_train)\n",
    "y_pred = LGB.predict(test_vectors_dbow)\n",
    "ypred_train = LGB.predict(train_vectors_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set 0.8588120740019474\n",
      "[[398  59   1]\n",
      " [ 46 461   5]\n",
      " [  4  30  23]]\n",
      "---------------------------\n",
      "Accuracy of training set 1.0\n",
      "[[489 537  68]\n",
      " [531 575  56]\n",
      " [ 69  62   9]]\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.89      0.87      0.88       458\n",
      "      Yellow       0.79      0.40      0.53        57\n",
      "         Red       0.84      0.90      0.87       512\n",
      "\n",
      "    accuracy                           0.86      1027\n",
      "   macro avg       0.84      0.72      0.76      1027\n",
      "weighted avg       0.86      0.86      0.85      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print('Accuracy of test set %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred, my_tags))\n",
    "print('---------------------------')\n",
    "print('Accuracy of training set %s' % accuracy_score(ypred_train, y_train))\n",
    "print(confusion_matrix(y_train, y_pred_train,my_tags))\n",
    "print('---------------------------')\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2396\n",
      "Test size: 1027\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data) * .7)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(data) - train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_posts = data['texts'][:train_size]\n",
    "train_tags = data['labels'][:train_size]\n",
    "\n",
    "test_posts = data['texts'][train_size:]\n",
    "test_tags = data['labels'][train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2396, 1000)\n",
      "x_test shape: (1027, 1000)\n",
      "y_train shape: (2396, 3)\n",
      "y_test shape: (1027, 3)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2156 samples, validate on 240 samples\n",
      "Epoch 1/2\n",
      "2156/2156 [==============================] - ETA: 5:47 - loss: 1.0651 - accuracy: 0.50 - ETA: 1:54 - loss: 1.0646 - accuracy: 0.52 - ETA: 46s - loss: 1.0339 - accuracy: 0.5938 - ETA: 25s - loss: 0.9890 - accuracy: 0.648 - ETA: 13s - loss: 0.9405 - accuracy: 0.687 - ETA: 9s - loss: 0.9008 - accuracy: 0.708 - ETA: 6s - loss: 0.8620 - accuracy: 0.73 - ETA: 4s - loss: 0.8298 - accuracy: 0.74 - ETA: 3s - loss: 0.7954 - accuracy: 0.75 - ETA: 2s - loss: 0.7704 - accuracy: 0.76 - ETA: 1s - loss: 0.7506 - accuracy: 0.76 - ETA: 0s - loss: 0.7250 - accuracy: 0.77 - ETA: 0s - loss: 0.7072 - accuracy: 0.77 - 6s 3ms/step - loss: 0.7020 - accuracy: 0.7788 - val_loss: 0.4521 - val_accuracy: 0.8542\n",
      "Epoch 2/2\n",
      "2156/2156 [==============================] - ETA: 0s - loss: 0.4934 - accuracy: 0.87 - ETA: 0s - loss: 0.4484 - accuracy: 0.84 - ETA: 0s - loss: 0.4331 - accuracy: 0.84 - ETA: 0s - loss: 0.4061 - accuracy: 0.85 - ETA: 0s - loss: 0.4037 - accuracy: 0.85 - ETA: 0s - loss: 0.4022 - accuracy: 0.85 - ETA: 0s - loss: 0.3965 - accuracy: 0.85 - ETA: 0s - loss: 0.3933 - accuracy: 0.85 - ETA: 0s - loss: 0.3873 - accuracy: 0.85 - ETA: 0s - loss: 0.3791 - accuracy: 0.86 - ETA: 0s - loss: 0.3817 - accuracy: 0.85 - ETA: 0s - loss: 0.3750 - accuracy: 0.85 - ETA: 0s - loss: 0.3723 - accuracy: 0.86 - 1s 324us/step - loss: 0.3725 - accuracy: 0.8622 - val_loss: 0.3663 - val_accuracy: 0.8583\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1027/1027 [==============================] - ETA:  - 0s 35us/step\n",
      "Test accuracy: 0.8354430198669434\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42884670586815826, 0.8354430198669434]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
